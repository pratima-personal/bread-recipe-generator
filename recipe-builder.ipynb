{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import pyLDAvis.sklearn\n",
    "from sklearn.decomposition import NMF\n",
    "import markovify\n",
    "import train_NN as trainer\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequency of each word in a list\n",
    "def wordlist_to_freq(wordlist):\n",
    "    wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "    return dict(list(zip(wordlist,wordfreq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dictionary according to descending frequency of words in recipe and return top N results\n",
    "def sorted_dict(worddict, N):\n",
    "    newdict = {k: v for k, v in sorted(worddict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return dict(list(newdict.items())[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top words from a list of topic\n",
    "def print_topic_top_words(model, vectorizer, n_top_words):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f'\\nTopic #:{topic_idx}')\n",
    "        print(' '.join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate multiple sentences using a Markov bigram model and calculate their scores\n",
    "def get_markov_sentence(model, iters, minLength=1):\n",
    "    sentences = {}\n",
    "    for i in range(iters): \n",
    "    modelGen = model.chain.gen()\n",
    "    prevPrevWord = \"___BEGIN__\"\n",
    "    prevWord = next(modelGen)\n",
    "    madeSentence = prevWord + \" \"\n",
    "    \n",
    "    totalScore = 0\n",
    "    numWords = 1\n",
    "    for curWord in modelGen:\n",
    "        madeSentence += curWord + \" \"\n",
    "        numWords += 1\n",
    "        totalScore += model.chain.model[(prevPrevWord, prevWord)][curWord]\n",
    "        prevPrevWord = prevWord\n",
    "        prevWord = curWord\n",
    "    \n",
    "    madeSentence = madeSentence.strip()\n",
    "    if numWords == 0: continue\n",
    "    if numWords < minLength: continue\n",
    "    if madeSentence in sentences: continue\n",
    "    \n",
    "    totalScore += model.chain.model[(prevPrevWord, prevWord)][\"___END__\"]\n",
    "    sentences[madeSentence] = totalScore/float(numWords)\n",
    "    sorted(sentences.items(), key=lambda x: -x[1])\n",
    "    return sentences.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from model\n",
    "def generate_sentence(model, tokenizer, sequence_length, starting_text, num_predicted_words):\n",
    "    prediction = [starting_text]\n",
    "    for _ in range(num_predicted_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([starting_text])[0]\n",
    "        encoded_text = pad_sequences([encoded_text], \n",
    "                                     maxlen=sequence_length, \n",
    "                                     truncating='pre')\n",
    "        preds = model.predict_classes(encoded_text, verbose=0)\n",
    "        out_word = ''\n",
    "        for word, idx in tokenizer.word_index.items():\n",
    "            if idx == preds:\n",
    "                out_word = word\n",
    "                break\n",
    "        starting_text += ' ' + out_word\n",
    "        prediction.append(out_word)\n",
    "    return ' '.join(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('data/recipeInfo.txt', 'r') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        data.append(line[:-2])\n",
    "        line = f.readline()\n",
    "f.close()\n",
    "\n",
    "df_recipe = pd.DataFrame(data, columns=['Recipe'])\n",
    "df_recipe['Length'] = df_recipe['Recipe'].apply(lambda x: len(x.split()))\n",
    "df_recipe['Unique Words'] = df_recipe['Recipe'].apply(lambda x: len(set(x.split())))\n",
    "df_recipe['Tokenized Recipe'] = df_recipe['Recipe'].apply(trainer.tokenize)\n",
    "df_recipe['Cleaned Recipe'] = df_recipe['Tokenized Recipe'].str.join(' ')\n",
    "df_recipe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "long_string = ','.join(list(df_recipe['Recipe'].values))\n",
    "wordcloud = WordCloud(background_color='white', max_words=100, contour_width=3, contour_color='steelblue')\n",
    "wordcloud.generate(long_string)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_split = [string.split(' ') for string in df_recipe['Recipe'].tolist()]\n",
    "word_list = [word.translate(str.maketrans('', '', string.punctuation)).lower() \n",
    "             for recipe in recipe_split for word in recipe]\n",
    "word_list = [word for word in word_list if word not in set(stopwords.words('english'))]\n",
    "word_dict = sorted_dict( wordlist_to_freq(word_list), 21 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(word_dict.items())[1:], columns=['Word', 'Frequency'])\n",
    "fig = px.bar(df, x=df['Word'], y=df['Frequency'], orientation='v')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_topics = 5\n",
    "number_words = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing LDA for topic modeling\n",
    "count_vectorizer = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "count_data = count_vectorizer.fit_transform(df_recipe['Cleaned Recipe'])\n",
    "\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1, learning_method='batch', max_iter=50, random_state=42)\n",
    "lda.fit(count_data)\n",
    "\n",
    "print('Topics found via LDA:')\n",
    "print_topic_top_words(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize topics using pyLDAvis package\n",
    " pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(lda, count_data, count_vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing NMF for topic modeling\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = tfidf_vectorizer.fit_transform(df_recipe['Cleaned Recipe'])\n",
    "\n",
    "nmf = NMF(n_components=number_topics, random_state=42)\n",
    "nmf.fit(doc_term_matrix)\n",
    "\n",
    "print('Topics found via NMF:')\n",
    "print_topic_top_words(nmf, tfidf_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Markov Chain model using markovify to predict text\n",
    "recipes = df_recipe['Cleaned Recipe'].tolist()\n",
    "text_model = markovify.NewlineText(recipes, state_size=2)\n",
    "for idx in range(2):\n",
    "    print(idx, text_model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(getSent(text_model, 500, 4))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained NN to generate sentences with word-level language model\n",
    "trained_model = load_model('model/recipe_model_epoch100.h5')\n",
    "with open('model/tokenizer_model.pkl', 'rb') as t:\n",
    "    tokenizer = pkl.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 20\n",
    "generate_sentence(trained_model, tokenizer, seq_length, 'i made bread', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
